{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "377129fd",
      "metadata": {},
      "source": [
        "# Multi-stage workflow for Reddit mood classifier\n",
        "\n",
        "1. ?????????? ingestion: `python python/data_pipeline.py --output python/data/combined_dataset.parquet` (????? `--skip-pushshift` ?????????????????????????????? timeout).\n",
        "2. ???????????????????? ??? training ???? GPU: `python python/train_gpu_transformer.py --data-path python/data/combined_dataset.parquet --output-dir model/transformer_distilbert`.\n",
        "3. ????????????????????????????????????????? timeout ??? training script ??? PyTorch + HuggingFace Transformers ????????? RTX 4070 Ti ???????????????????????????????? (??? `torch.cuda.is_available()`).\n",
        "\n",
        "?????????????????????????????????????????? ??????? helper ??????????????????????????????????????????? ?."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9f138e36",
      "metadata": {},
      "outputs": [],
      "source": [
        "import subprocess\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "DATA_PATH = Path('python/data/combined_dataset.parquet')\n",
        "STATS_PATH = Path('python/data/combined_dataset_stats.json')\n",
        "MODEL_DIR = Path('model/transformer_distilbert')\n",
        "\n",
        "BASE_DATA_CMD = [\n",
        "    sys.executable, 'python/data_pipeline.py',\n",
        "    '--output', str(DATA_PATH),\n",
        "    '--stats-output', str(STATS_PATH),\n",
        "]\n",
        "\n",
        "BASE_TRAIN_CMD = [\n",
        "    sys.executable, 'python/train_gpu_transformer.py',\n",
        "    '--data-path', str(DATA_PATH),\n",
        "    '--output-dir', str(MODEL_DIR),\n",
        "]\n",
        "\n",
        "def run_data_pipeline(skip_pushshift: bool = True, max_per_label: int | None = None):\n",
        "    cmd = BASE_DATA_CMD.copy()\n",
        "    if skip_pushshift:\n",
        "        cmd.append('--skip-pushshift')\n",
        "    if max_per_label:\n",
        "        cmd += ['--sample-per-label', str(max_per_label)]\n",
        "    subprocess.run(cmd, check=True)\n",
        "\n",
        "def run_gpu_training(max_per_label: int | None = None, epochs: float | None = None):\n",
        "    cmd = BASE_TRAIN_CMD.copy()\n",
        "    if max_per_label:\n",
        "        cmd += ['--max-per-label', str(max_per_label)]\n",
        "    if epochs:\n",
        "        cmd += ['--epochs', str(epochs)]\n",
        "    subprocess.run(cmd, check=True)\n",
        "\n",
        "print(f'Dataset target: {DATA_PATH.resolve()}')\n",
        "print(f'Model directory: {MODEL_DIR.resolve()}')\n",
        "print('Call run_data_pipeline() and run_gpu_training() as needed.')\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Ai",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
